{
  "best_global_step": 11000,
  "best_metric": 38.80053383751321,
  "best_model_checkpoint": "output/checkpoint-11000",
  "epoch": 29.412177985948478,
  "eval_steps": 500,
  "global_step": 11000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.13382402141184344,
      "grad_norm": 7.866619110107422,
      "learning_rate": 9.800000000000001e-06,
      "loss": 1.8552,
      "step": 50
    },
    {
      "epoch": 0.26764804282368687,
      "grad_norm": 6.365644454956055,
      "learning_rate": 1.9800000000000004e-05,
      "loss": 1.3176,
      "step": 100
    },
    {
      "epoch": 0.4014720642355303,
      "grad_norm": 4.93337345123291,
      "learning_rate": 2.98e-05,
      "loss": 1.0499,
      "step": 150
    },
    {
      "epoch": 0.5352960856473737,
      "grad_norm": 6.579518795013428,
      "learning_rate": 3.9800000000000005e-05,
      "loss": 0.8615,
      "step": 200
    },
    {
      "epoch": 0.6691201070592171,
      "grad_norm": 7.036129951477051,
      "learning_rate": 4.9800000000000004e-05,
      "loss": 0.6989,
      "step": 250
    },
    {
      "epoch": 0.8029441284710606,
      "grad_norm": 5.645998954772949,
      "learning_rate": 5.9800000000000003e-05,
      "loss": 0.6497,
      "step": 300
    },
    {
      "epoch": 0.936768149882904,
      "grad_norm": 4.992225170135498,
      "learning_rate": 6.98e-05,
      "loss": 0.6321,
      "step": 350
    },
    {
      "epoch": 1.0695884911341587,
      "grad_norm": 6.807543754577637,
      "learning_rate": 7.98e-05,
      "loss": 0.6086,
      "step": 400
    },
    {
      "epoch": 1.203412512546002,
      "grad_norm": 4.6353631019592285,
      "learning_rate": 8.98e-05,
      "loss": 0.5737,
      "step": 450
    },
    {
      "epoch": 1.3372365339578454,
      "grad_norm": 5.099527835845947,
      "learning_rate": 9.98e-05,
      "loss": 0.5557,
      "step": 500
    },
    {
      "epoch": 1.3372365339578454,
      "eval_cer": 125.5602513484958,
      "eval_loss": 0.8389779925346375,
      "eval_runtime": 5301.3881,
      "eval_samples_per_second": 0.282,
      "eval_steps_per_second": 0.071,
      "eval_wer": 92.7710843373494,
      "step": 500
    },
    {
      "epoch": 1.471060555369689,
      "grad_norm": 4.35355281829834,
      "learning_rate": 0.00010980000000000001,
      "loss": 0.5526,
      "step": 550
    },
    {
      "epoch": 1.6048845767815323,
      "grad_norm": 5.491440773010254,
      "learning_rate": 0.0001198,
      "loss": 0.5613,
      "step": 600
    },
    {
      "epoch": 1.7387085981933756,
      "grad_norm": 2.883718252182007,
      "learning_rate": 0.0001298,
      "loss": 0.539,
      "step": 650
    },
    {
      "epoch": 1.8725326196052192,
      "grad_norm": 4.001646518707275,
      "learning_rate": 0.0001398,
      "loss": 0.5333,
      "step": 700
    },
    {
      "epoch": 2.0053529608564737,
      "grad_norm": 4.24423360824585,
      "learning_rate": 0.0001498,
      "loss": 0.5,
      "step": 750
    },
    {
      "epoch": 2.1391769822683173,
      "grad_norm": 4.338840484619141,
      "learning_rate": 0.0001598,
      "loss": 0.4968,
      "step": 800
    },
    {
      "epoch": 2.2730010036801604,
      "grad_norm": 2.623319625854492,
      "learning_rate": 0.0001698,
      "loss": 0.4648,
      "step": 850
    },
    {
      "epoch": 2.406825025092004,
      "grad_norm": 2.7400259971618652,
      "learning_rate": 0.0001798,
      "loss": 0.4957,
      "step": 900
    },
    {
      "epoch": 2.5406490465038476,
      "grad_norm": 2.282782793045044,
      "learning_rate": 0.0001898,
      "loss": 0.4682,
      "step": 950
    },
    {
      "epoch": 2.6744730679156907,
      "grad_norm": 3.3078043460845947,
      "learning_rate": 0.0001998,
      "loss": 0.4793,
      "step": 1000
    },
    {
      "epoch": 2.6744730679156907,
      "eval_cer": 113.90757938052604,
      "eval_loss": 0.7293314933776855,
      "eval_runtime": 5019.9199,
      "eval_samples_per_second": 0.298,
      "eval_steps_per_second": 0.075,
      "eval_wer": 91.36546184738957,
      "step": 1000
    },
    {
      "epoch": 2.8082970893275343,
      "grad_norm": 4.151055812835693,
      "learning_rate": 0.00019998865637379468,
      "loss": 0.4777,
      "step": 1050
    },
    {
      "epoch": 2.942121110739378,
      "grad_norm": 2.3137621879577637,
      "learning_rate": 0.0001999536974585086,
      "loss": 0.4961,
      "step": 1100
    },
    {
      "epoch": 3.0749414519906324,
      "grad_norm": 2.855088949203491,
      "learning_rate": 0.00019989512678774755,
      "loss": 0.427,
      "step": 1150
    },
    {
      "epoch": 3.208765473402476,
      "grad_norm": 2.421529531478882,
      "learning_rate": 0.00019981295819748146,
      "loss": 0.4271,
      "step": 1200
    },
    {
      "epoch": 3.342589494814319,
      "grad_norm": 3.4018657207489014,
      "learning_rate": 0.00019970721109814448,
      "loss": 0.4341,
      "step": 1250
    },
    {
      "epoch": 3.4764135162261627,
      "grad_norm": 2.4932713508605957,
      "learning_rate": 0.00019957791047004966,
      "loss": 0.4347,
      "step": 1300
    },
    {
      "epoch": 3.610237537638006,
      "grad_norm": 2.269827127456665,
      "learning_rate": 0.0001994250868574879,
      "loss": 0.4236,
      "step": 1350
    },
    {
      "epoch": 3.7440615590498494,
      "grad_norm": 2.778160333633423,
      "learning_rate": 0.00019924877636151258,
      "loss": 0.4281,
      "step": 1400
    },
    {
      "epoch": 3.877885580461693,
      "grad_norm": 2.2737576961517334,
      "learning_rate": 0.0001990490206314116,
      "loss": 0.4155,
      "step": 1450
    },
    {
      "epoch": 4.0107059217129475,
      "grad_norm": 3.262096405029297,
      "learning_rate": 0.00019882586685486862,
      "loss": 0.4173,
      "step": 1500
    },
    {
      "epoch": 4.0107059217129475,
      "eval_cer": 107.01773897569926,
      "eval_loss": 0.6947653293609619,
      "eval_runtime": 5076.8042,
      "eval_samples_per_second": 0.294,
      "eval_steps_per_second": 0.074,
      "eval_wer": 88.62115127175369,
      "step": 1500
    },
    {
      "epoch": 4.144529943124791,
      "grad_norm": 3.057474136352539,
      "learning_rate": 0.00019857936774681601,
      "loss": 0.3756,
      "step": 1550
    },
    {
      "epoch": 4.278353964536635,
      "grad_norm": 3.2897231578826904,
      "learning_rate": 0.00019830958153698225,
      "loss": 0.4138,
      "step": 1600
    },
    {
      "epoch": 4.412177985948478,
      "grad_norm": 2.321502208709717,
      "learning_rate": 0.00019801657195613647,
      "loss": 0.3865,
      "step": 1650
    },
    {
      "epoch": 4.546002007360321,
      "grad_norm": 2.0366692543029785,
      "learning_rate": 0.00019770040822103356,
      "loss": 0.3788,
      "step": 1700
    },
    {
      "epoch": 4.6798260287721645,
      "grad_norm": 2.5338077545166016,
      "learning_rate": 0.00019736116501806324,
      "loss": 0.3643,
      "step": 1750
    },
    {
      "epoch": 4.813650050184008,
      "grad_norm": 2.949622392654419,
      "learning_rate": 0.0001969989224856072,
      "loss": 0.3946,
      "step": 1800
    },
    {
      "epoch": 4.947474071595852,
      "grad_norm": 2.7966742515563965,
      "learning_rate": 0.00019661376619510814,
      "loss": 0.3817,
      "step": 1850
    },
    {
      "epoch": 5.080294412847106,
      "grad_norm": 2.5003795623779297,
      "learning_rate": 0.00019620578713085564,
      "loss": 0.3684,
      "step": 1900
    },
    {
      "epoch": 5.21411843425895,
      "grad_norm": 2.6180248260498047,
      "learning_rate": 0.00019577508166849304,
      "loss": 0.3584,
      "step": 1950
    },
    {
      "epoch": 5.347942455670793,
      "grad_norm": 2.401754856109619,
      "learning_rate": 0.0001953217515522512,
      "loss": 0.361,
      "step": 2000
    },
    {
      "epoch": 5.347942455670793,
      "eval_cer": 72.29605738753267,
      "eval_loss": 0.6486114859580994,
      "eval_runtime": 4531.9105,
      "eval_samples_per_second": 0.33,
      "eval_steps_per_second": 0.083,
      "eval_wer": 85.47523427041499,
      "step": 2000
    },
    {
      "epoch": 5.481766477082636,
      "grad_norm": 2.125554084777832,
      "learning_rate": 0.00019484590387091341,
      "loss": 0.3587,
      "step": 2050
    },
    {
      "epoch": 5.6155904984944796,
      "grad_norm": 2.7759718894958496,
      "learning_rate": 0.00019434765103251844,
      "loss": 0.3562,
      "step": 2100
    },
    {
      "epoch": 5.749414519906323,
      "grad_norm": 2.248323440551758,
      "learning_rate": 0.00019383773917408642,
      "loss": 0.3544,
      "step": 2150
    },
    {
      "epoch": 5.883238541318167,
      "grad_norm": 2.8439464569091797,
      "learning_rate": 0.00019329547643953112,
      "loss": 0.3601,
      "step": 2200
    },
    {
      "epoch": 6.016058882569421,
      "grad_norm": 2.4810638427734375,
      "learning_rate": 0.00019273117480063685,
      "loss": 0.3578,
      "step": 2250
    },
    {
      "epoch": 6.149882903981265,
      "grad_norm": 3.481887102127075,
      "learning_rate": 0.00019214496756064952,
      "loss": 0.3067,
      "step": 2300
    },
    {
      "epoch": 6.283706925393108,
      "grad_norm": 3.022327423095703,
      "learning_rate": 0.00019153699319750803,
      "loss": 0.3365,
      "step": 2350
    },
    {
      "epoch": 6.417530946804952,
      "grad_norm": 2.9181838035583496,
      "learning_rate": 0.00019090739533113204,
      "loss": 0.3447,
      "step": 2400
    },
    {
      "epoch": 6.551354968216795,
      "grad_norm": 1.6217656135559082,
      "learning_rate": 0.00019025632268949508,
      "loss": 0.3649,
      "step": 2450
    },
    {
      "epoch": 6.685178989628638,
      "grad_norm": 1.9172133207321167,
      "learning_rate": 0.0001895839290734909,
      "loss": 0.3185,
      "step": 2500
    },
    {
      "epoch": 6.685178989628638,
      "eval_cer": 80.46766390479898,
      "eval_loss": 0.6425818204879761,
      "eval_runtime": 4765.6342,
      "eval_samples_per_second": 0.313,
      "eval_steps_per_second": 0.078,
      "eval_wer": 85.14056224899599,
      "step": 2500
    },
    {
      "epoch": 6.819003011040482,
      "grad_norm": 2.742218255996704,
      "learning_rate": 0.00018889037332060177,
      "loss": 0.3547,
      "step": 2550
    },
    {
      "epoch": 6.952827032452325,
      "grad_norm": 2.2612569332122803,
      "learning_rate": 0.00018817581926737668,
      "loss": 0.3448,
      "step": 2600
    },
    {
      "epoch": 7.08564737370358,
      "grad_norm": 1.4149938821792603,
      "learning_rate": 0.00018744043571072863,
      "loss": 0.3168,
      "step": 2650
    },
    {
      "epoch": 7.2194713951154235,
      "grad_norm": 2.117081880569458,
      "learning_rate": 0.00018669971843445908,
      "loss": 0.3314,
      "step": 2700
    },
    {
      "epoch": 7.353295416527267,
      "grad_norm": 2.485663414001465,
      "learning_rate": 0.00018592360966480242,
      "loss": 0.3124,
      "step": 2750
    },
    {
      "epoch": 7.48711943793911,
      "grad_norm": 2.077267646789551,
      "learning_rate": 0.00018512720342429156,
      "loss": 0.31,
      "step": 2800
    },
    {
      "epoch": 7.620943459350953,
      "grad_norm": 2.0810625553131104,
      "learning_rate": 0.00018431068784553073,
      "loss": 0.3194,
      "step": 2850
    },
    {
      "epoch": 7.754767480762797,
      "grad_norm": 2.008784055709839,
      "learning_rate": 0.00018347425581149158,
      "loss": 0.3222,
      "step": 2900
    },
    {
      "epoch": 7.8885915021746404,
      "grad_norm": 2.3163225650787354,
      "learning_rate": 0.00018261810490994884,
      "loss": 0.3353,
      "step": 2950
    },
    {
      "epoch": 8.021411843425895,
      "grad_norm": 2.2310800552368164,
      "learning_rate": 0.00018174243738680484,
      "loss": 0.3207,
      "step": 3000
    },
    {
      "epoch": 8.021411843425895,
      "eval_cer": 81.12383918144914,
      "eval_loss": 0.617413341999054,
      "eval_runtime": 4685.698,
      "eval_samples_per_second": 0.319,
      "eval_steps_per_second": 0.08,
      "eval_wer": 85.27443105756359,
      "step": 3000
    },
    {
      "epoch": 8.155235864837739,
      "grad_norm": 2.5296177864074707,
      "learning_rate": 0.0001808474600983137,
      "loss": 0.2936,
      "step": 3050
    },
    {
      "epoch": 8.289059886249582,
      "grad_norm": 2.4753856658935547,
      "learning_rate": 0.0001799333844622161,
      "loss": 0.3144,
      "step": 3100
    },
    {
      "epoch": 8.422883907661426,
      "grad_norm": 2.65623140335083,
      "learning_rate": 0.00017900042640779675,
      "loss": 0.2943,
      "step": 3150
    },
    {
      "epoch": 8.55670792907327,
      "grad_norm": 3.4391932487487793,
      "learning_rate": 0.00017804880632487632,
      "loss": 0.2893,
      "step": 3200
    },
    {
      "epoch": 8.690531950485113,
      "grad_norm": 2.2204177379608154,
      "learning_rate": 0.00017707874901174914,
      "loss": 0.3171,
      "step": 3250
    },
    {
      "epoch": 8.824355971896956,
      "grad_norm": 3.0038094520568848,
      "learning_rate": 0.00017609048362207994,
      "loss": 0.3164,
      "step": 3300
    },
    {
      "epoch": 8.958179993308798,
      "grad_norm": 2.81316876411438,
      "learning_rate": 0.00017508424361077152,
      "loss": 0.3047,
      "step": 3350
    },
    {
      "epoch": 9.091000334560054,
      "grad_norm": 2.4088382720947266,
      "learning_rate": 0.0001740809184815821,
      "loss": 0.3246,
      "step": 3400
    },
    {
      "epoch": 9.224824355971897,
      "grad_norm": 2.2798595428466797,
      "learning_rate": 0.00017303979402314833,
      "loss": 0.2908,
      "step": 3450
    },
    {
      "epoch": 9.35864837738374,
      "grad_norm": 3.4830875396728516,
      "learning_rate": 0.00017198141559812534,
      "loss": 0.2734,
      "step": 3500
    },
    {
      "epoch": 9.35864837738374,
      "eval_cer": 60.076183061780576,
      "eval_loss": 0.6200463175773621,
      "eval_runtime": 4245.8205,
      "eval_samples_per_second": 0.352,
      "eval_steps_per_second": 0.088,
      "eval_wer": 83.13253012048193,
      "step": 3500
    },
    {
      "epoch": 9.492472398795584,
      "grad_norm": 3.5304605960845947,
      "learning_rate": 0.00017090603322400327,
      "loss": 0.2899,
      "step": 3550
    },
    {
      "epoch": 9.626296420207428,
      "grad_norm": 3.8040199279785156,
      "learning_rate": 0.0001698139009350631,
      "loss": 0.2988,
      "step": 3600
    },
    {
      "epoch": 9.760120441619272,
      "grad_norm": 2.374903440475464,
      "learning_rate": 0.0001687052767223667,
      "loss": 0.3017,
      "step": 3650
    },
    {
      "epoch": 9.893944463031113,
      "grad_norm": 2.0508527755737305,
      "learning_rate": 0.0001675804224728127,
      "loss": 0.2836,
      "step": 3700
    },
    {
      "epoch": 10.026764804282369,
      "grad_norm": 2.9745230674743652,
      "learning_rate": 0.0001664396039072714,
      "loss": 0.3026,
      "step": 3750
    },
    {
      "epoch": 10.160588825694212,
      "grad_norm": 1.8031505346298218,
      "learning_rate": 0.00016528309051781455,
      "loss": 0.2771,
      "step": 3800
    },
    {
      "epoch": 10.294412847106056,
      "grad_norm": 1.8050434589385986,
      "learning_rate": 0.0001641111555040542,
      "loss": 0.273,
      "step": 3850
    },
    {
      "epoch": 10.4282368685179,
      "grad_norm": 1.693174958229065,
      "learning_rate": 0.00016292407570860518,
      "loss": 0.2936,
      "step": 3900
    },
    {
      "epoch": 10.562060889929743,
      "grad_norm": 1.746751308441162,
      "learning_rate": 0.00016172213155168783,
      "loss": 0.2556,
      "step": 3950
    },
    {
      "epoch": 10.695884911341587,
      "grad_norm": 1.9358141422271729,
      "learning_rate": 0.00016050560696488492,
      "loss": 0.2837,
      "step": 4000
    },
    {
      "epoch": 10.695884911341587,
      "eval_cer": 90.0044486459434,
      "eval_loss": 0.6163778901100159,
      "eval_runtime": 4917.1752,
      "eval_samples_per_second": 0.304,
      "eval_steps_per_second": 0.076,
      "eval_wer": 87.55020080321285,
      "step": 4000
    },
    {
      "epoch": 10.82970893275343,
      "grad_norm": 1.7756587266921997,
      "learning_rate": 0.00015927478932406953,
      "loss": 0.277,
      "step": 4050
    },
    {
      "epoch": 10.963532954165272,
      "grad_norm": 2.7659871578216553,
      "learning_rate": 0.00015802996938151905,
      "loss": 0.278,
      "step": 4100
    },
    {
      "epoch": 11.096353295416527,
      "grad_norm": 1.8902313709259033,
      "learning_rate": 0.0001567714411972317,
      "loss": 0.2771,
      "step": 4150
    },
    {
      "epoch": 11.230177316828371,
      "grad_norm": 1.5409650802612305,
      "learning_rate": 0.00015549950206946152,
      "loss": 0.2535,
      "step": 4200
    },
    {
      "epoch": 11.364001338240215,
      "grad_norm": 1.7873010635375977,
      "learning_rate": 0.00015421445246448877,
      "loss": 0.2546,
      "step": 4250
    },
    {
      "epoch": 11.497825359652058,
      "grad_norm": 3.2435696125030518,
      "learning_rate": 0.00015291659594564134,
      "loss": 0.2698,
      "step": 4300
    },
    {
      "epoch": 11.631649381063902,
      "grad_norm": 1.416697382926941,
      "learning_rate": 0.00015160623910158528,
      "loss": 0.25,
      "step": 4350
    },
    {
      "epoch": 11.765473402475745,
      "grad_norm": 2.1586339473724365,
      "learning_rate": 0.00015028369147390005,
      "loss": 0.2709,
      "step": 4400
    },
    {
      "epoch": 11.899297423887587,
      "grad_norm": 2.2298436164855957,
      "learning_rate": 0.00014894926548395662,
      "loss": 0.2767,
      "step": 4450
    },
    {
      "epoch": 12.032117765138842,
      "grad_norm": 1.6076998710632324,
      "learning_rate": 0.00014760327635911496,
      "loss": 0.2809,
      "step": 4500
    },
    {
      "epoch": 12.032117765138842,
      "eval_cer": 60.76572318300617,
      "eval_loss": 0.6101785898208618,
      "eval_runtime": 4340.5236,
      "eval_samples_per_second": 0.344,
      "eval_steps_per_second": 0.086,
      "eval_wer": 83.46720214190094,
      "step": 4500
    },
    {
      "epoch": 12.165941786550686,
      "grad_norm": 1.442310094833374,
      "learning_rate": 0.00014624604205825902,
      "loss": 0.2547,
      "step": 4550
    },
    {
      "epoch": 12.29976580796253,
      "grad_norm": 2.877333879470825,
      "learning_rate": 0.00014487788319668616,
      "loss": 0.2622,
      "step": 4600
    },
    {
      "epoch": 12.433589829374373,
      "grad_norm": 3.0814106464385986,
      "learning_rate": 0.00014349912297036921,
      "loss": 0.2524,
      "step": 4650
    },
    {
      "epoch": 12.567413850786217,
      "grad_norm": 2.533517360687256,
      "learning_rate": 0.00014211008707960897,
      "loss": 0.2517,
      "step": 4700
    },
    {
      "epoch": 12.70123787219806,
      "grad_norm": 2.686500072479248,
      "learning_rate": 0.00014071110365209484,
      "loss": 0.2583,
      "step": 4750
    },
    {
      "epoch": 12.835061893609904,
      "grad_norm": 2.315091609954834,
      "learning_rate": 0.00013930250316539238,
      "loss": 0.2435,
      "step": 4800
    },
    {
      "epoch": 12.968885915021746,
      "grad_norm": 1.5567458868026733,
      "learning_rate": 0.00013788461836887556,
      "loss": 0.256,
      "step": 4850
    },
    {
      "epoch": 13.101706256273001,
      "grad_norm": 2.436631679534912,
      "learning_rate": 0.00013645778420512235,
      "loss": 0.2438,
      "step": 4900
    },
    {
      "epoch": 13.235530277684845,
      "grad_norm": 1.9986169338226318,
      "learning_rate": 0.00013502233773079236,
      "loss": 0.2507,
      "step": 4950
    },
    {
      "epoch": 13.369354299096688,
      "grad_norm": 2.436607599258423,
      "learning_rate": 0.00013357861803700488,
      "loss": 0.2349,
      "step": 5000
    },
    {
      "epoch": 13.369354299096688,
      "eval_cer": 48.1621531446366,
      "eval_loss": 0.6128671765327454,
      "eval_runtime": 3981.7244,
      "eval_samples_per_second": 0.375,
      "eval_steps_per_second": 0.094,
      "eval_wer": 83.13253012048193,
      "step": 5000
    },
    {
      "epoch": 13.503178320508532,
      "grad_norm": 2.0460364818573,
      "learning_rate": 0.00013212696616923646,
      "loss": 0.23,
      "step": 5050
    },
    {
      "epoch": 13.637002341920375,
      "grad_norm": 2.1360690593719482,
      "learning_rate": 0.00013066772504675682,
      "loss": 0.2475,
      "step": 5100
    },
    {
      "epoch": 13.770826363332219,
      "grad_norm": 1.7571457624435425,
      "learning_rate": 0.00012920123938162204,
      "loss": 0.2369,
      "step": 5150
    },
    {
      "epoch": 13.90465038474406,
      "grad_norm": 5.169754981994629,
      "learning_rate": 0.00012772785559724424,
      "loss": 0.243,
      "step": 5200
    },
    {
      "epoch": 14.037470725995316,
      "grad_norm": 2.0657694339752197,
      "learning_rate": 0.0001262479217465572,
      "loss": 0.2464,
      "step": 5250
    },
    {
      "epoch": 14.17129474740716,
      "grad_norm": 1.5460718870162964,
      "learning_rate": 0.00012476178742979675,
      "loss": 0.225,
      "step": 5300
    },
    {
      "epoch": 14.305118768819003,
      "grad_norm": 2.4331138134002686,
      "learning_rate": 0.00012326980371191575,
      "loss": 0.2312,
      "step": 5350
    },
    {
      "epoch": 14.438942790230847,
      "grad_norm": 1.8906856775283813,
      "learning_rate": 0.0001217723230396532,
      "loss": 0.2355,
      "step": 5400
    },
    {
      "epoch": 14.57276681164269,
      "grad_norm": 1.607606053352356,
      "learning_rate": 0.00012026969915827675,
      "loss": 0.2261,
      "step": 5450
    },
    {
      "epoch": 14.706590833054534,
      "grad_norm": 2.6495673656463623,
      "learning_rate": 0.00011876228702801862,
      "loss": 0.232,
      "step": 5500
    },
    {
      "epoch": 14.706590833054534,
      "eval_cer": 47.98142690318634,
      "eval_loss": 0.6025280952453613,
      "eval_runtime": 4103.5997,
      "eval_samples_per_second": 0.364,
      "eval_steps_per_second": 0.091,
      "eval_wer": 82.39625167336011,
      "step": 5500
    },
    {
      "epoch": 14.840414854466378,
      "grad_norm": 2.646829843521118,
      "learning_rate": 0.00011725044274022431,
      "loss": 0.2423,
      "step": 5550
    },
    {
      "epoch": 14.97423887587822,
      "grad_norm": 1.9677362442016602,
      "learning_rate": 0.00011573452343323439,
      "loss": 0.2282,
      "step": 5600
    },
    {
      "epoch": 15.107059217129475,
      "grad_norm": 6.619710445404053,
      "learning_rate": 0.00011421488720801866,
      "loss": 0.2222,
      "step": 5650
    },
    {
      "epoch": 15.240883238541318,
      "grad_norm": 1.3692580461502075,
      "learning_rate": 0.0001126918930435831,
      "loss": 0.2178,
      "step": 5700
    },
    {
      "epoch": 15.374707259953162,
      "grad_norm": 3.6693880558013916,
      "learning_rate": 0.00011116590071216945,
      "loss": 0.2138,
      "step": 5750
    },
    {
      "epoch": 15.508531281365006,
      "grad_norm": 2.5909852981567383,
      "learning_rate": 0.0001096372706942672,
      "loss": 0.2248,
      "step": 5800
    },
    {
      "epoch": 15.64235530277685,
      "grad_norm": 1.4736889600753784,
      "learning_rate": 0.00010810636409345838,
      "loss": 0.2059,
      "step": 5850
    },
    {
      "epoch": 15.776179324188693,
      "grad_norm": 1.3510894775390625,
      "learning_rate": 0.00010657354255111532,
      "loss": 0.2156,
      "step": 5900
    },
    {
      "epoch": 15.910003345600535,
      "grad_norm": 2.6993911266326904,
      "learning_rate": 0.00010503916816097104,
      "loss": 0.2154,
      "step": 5950
    },
    {
      "epoch": 16.04282368685179,
      "grad_norm": 1.8803117275238037,
      "learning_rate": 0.00010350360338358308,
      "loss": 0.218,
      "step": 6000
    },
    {
      "epoch": 16.04282368685179,
      "eval_cer": 51.590390924762275,
      "eval_loss": 0.6128625869750977,
      "eval_runtime": 4261.8719,
      "eval_samples_per_second": 0.351,
      "eval_steps_per_second": 0.088,
      "eval_wer": 82.79785809906292,
      "step": 6000
    },
    {
      "epoch": 16.176647708263634,
      "grad_norm": 2.005422353744507,
      "learning_rate": 0.00010196721096071047,
      "loss": 0.2226,
      "step": 6050
    },
    {
      "epoch": 16.310471729675477,
      "grad_norm": 1.6973499059677124,
      "learning_rate": 0.00010043035382962443,
      "loss": 0.2087,
      "step": 6100
    },
    {
      "epoch": 16.44429575108732,
      "grad_norm": 1.645785927772522,
      "learning_rate": 9.889339503737274e-05,
      "loss": 0.1901,
      "step": 6150
    },
    {
      "epoch": 16.578119772499164,
      "grad_norm": 1.813002347946167,
      "learning_rate": 9.735669765501836e-05,
      "loss": 0.2142,
      "step": 6200
    },
    {
      "epoch": 16.711943793911008,
      "grad_norm": 1.8568252325057983,
      "learning_rate": 9.58206246918721e-05,
      "loss": 0.1987,
      "step": 6250
    },
    {
      "epoch": 16.84576781532285,
      "grad_norm": 2.1974921226501465,
      "learning_rate": 9.428553900974017e-05,
      "loss": 0.2122,
      "step": 6300
    },
    {
      "epoch": 16.979591836734695,
      "grad_norm": 2.219850540161133,
      "learning_rate": 9.27518032372064e-05,
      "loss": 0.2125,
      "step": 6350
    },
    {
      "epoch": 17.11241217798595,
      "grad_norm": 2.2773613929748535,
      "learning_rate": 9.121977968396969e-05,
      "loss": 0.1897,
      "step": 6400
    },
    {
      "epoch": 17.246236199397792,
      "grad_norm": 1.55328369140625,
      "learning_rate": 8.968983025525654e-05,
      "loss": 0.1947,
      "step": 6450
    },
    {
      "epoch": 17.380060220809636,
      "grad_norm": 1.3498188257217407,
      "learning_rate": 8.816231636632939e-05,
      "loss": 0.1916,
      "step": 6500
    },
    {
      "epoch": 17.380060220809636,
      "eval_cer": 55.37452038035923,
      "eval_loss": 0.6120104193687439,
      "eval_runtime": 4389.9758,
      "eval_samples_per_second": 0.34,
      "eval_steps_per_second": 0.085,
      "eval_wer": 83.80187416331995,
      "step": 6500
    },
    {
      "epoch": 17.51388424222148,
      "grad_norm": 1.5419780015945435,
      "learning_rate": 8.663759885711055e-05,
      "loss": 0.2149,
      "step": 6550
    },
    {
      "epoch": 17.647708263633323,
      "grad_norm": 1.4858819246292114,
      "learning_rate": 8.511603790694228e-05,
      "loss": 0.1934,
      "step": 6600
    },
    {
      "epoch": 17.781532285045166,
      "grad_norm": 1.343173623085022,
      "learning_rate": 8.359799294950239e-05,
      "loss": 0.1968,
      "step": 6650
    },
    {
      "epoch": 17.91535630645701,
      "grad_norm": 1.9744113683700562,
      "learning_rate": 8.208382258789662e-05,
      "loss": 0.2003,
      "step": 6700
    },
    {
      "epoch": 18.048176647708264,
      "grad_norm": 3.6894474029541016,
      "learning_rate": 8.057388450994669e-05,
      "loss": 0.1837,
      "step": 6750
    },
    {
      "epoch": 18.182000669120107,
      "grad_norm": 1.3947255611419678,
      "learning_rate": 7.906853540369514e-05,
      "loss": 0.1885,
      "step": 6800
    },
    {
      "epoch": 18.31582469053195,
      "grad_norm": 1.7462754249572754,
      "learning_rate": 7.756813087314563e-05,
      "loss": 0.1862,
      "step": 6850
    },
    {
      "epoch": 18.449648711943794,
      "grad_norm": 1.2884435653686523,
      "learning_rate": 7.607302535425989e-05,
      "loss": 0.1801,
      "step": 6900
    },
    {
      "epoch": 18.583472733355638,
      "grad_norm": 3.294926166534424,
      "learning_rate": 7.458357203123038e-05,
      "loss": 0.1876,
      "step": 6950
    },
    {
      "epoch": 18.71729675476748,
      "grad_norm": 1.1978299617767334,
      "learning_rate": 7.310012275304871e-05,
      "loss": 0.1727,
      "step": 7000
    },
    {
      "epoch": 18.71729675476748,
      "eval_cer": 47.47539342712562,
      "eval_loss": 0.6232897639274597,
      "eval_runtime": 4171.105,
      "eval_samples_per_second": 0.358,
      "eval_steps_per_second": 0.09,
      "eval_wer": 83.06559571619813,
      "step": 7000
    },
    {
      "epoch": 18.851120776179325,
      "grad_norm": 1.9893327951431274,
      "learning_rate": 7.162302795038932e-05,
      "loss": 0.2003,
      "step": 7050
    },
    {
      "epoch": 18.98494479759117,
      "grad_norm": 1.11408531665802,
      "learning_rate": 7.015263655282843e-05,
      "loss": 0.1921,
      "step": 7100
    },
    {
      "epoch": 19.117765138842422,
      "grad_norm": 1.5741418600082397,
      "learning_rate": 6.868929590641735e-05,
      "loss": 0.1693,
      "step": 7150
    },
    {
      "epoch": 19.251589160254266,
      "grad_norm": 3.2658016681671143,
      "learning_rate": 6.72333516916302e-05,
      "loss": 0.1757,
      "step": 7200
    },
    {
      "epoch": 19.38541318166611,
      "grad_norm": 1.4341219663619995,
      "learning_rate": 6.578514784170464e-05,
      "loss": 0.1753,
      "step": 7250
    },
    {
      "epoch": 19.519237203077953,
      "grad_norm": 1.8959684371948242,
      "learning_rate": 6.434502646139564e-05,
      "loss": 0.1762,
      "step": 7300
    },
    {
      "epoch": 19.653061224489797,
      "grad_norm": 1.741518497467041,
      "learning_rate": 6.291332774616126e-05,
      "loss": 0.1843,
      "step": 7350
    },
    {
      "epoch": 19.78688524590164,
      "grad_norm": 3.3498194217681885,
      "learning_rate": 6.149038990179916e-05,
      "loss": 0.1815,
      "step": 7400
    },
    {
      "epoch": 19.920709267313484,
      "grad_norm": 1.431221842765808,
      "learning_rate": 6.007654906455331e-05,
      "loss": 0.181,
      "step": 7450
    },
    {
      "epoch": 20.053529608564737,
      "grad_norm": 1.5084402561187744,
      "learning_rate": 5.8672139221709577e-05,
      "loss": 0.1582,
      "step": 7500
    },
    {
      "epoch": 20.053529608564737,
      "eval_cer": 43.941500305844414,
      "eval_loss": 0.6341590285301208,
      "eval_runtime": 4107.5566,
      "eval_samples_per_second": 0.364,
      "eval_steps_per_second": 0.091,
      "eval_wer": 83.13253012048193,
      "step": 7500
    },
    {
      "epoch": 20.18735362997658,
      "grad_norm": 1.1137275695800781,
      "learning_rate": 5.727749213269904e-05,
      "loss": 0.1553,
      "step": 7550
    },
    {
      "epoch": 20.321177651388425,
      "grad_norm": 1.7995216846466064,
      "learning_rate": 5.5892937250727264e-05,
      "loss": 0.1736,
      "step": 7600
    },
    {
      "epoch": 20.455001672800268,
      "grad_norm": 1.9998810291290283,
      "learning_rate": 5.4518801644948735e-05,
      "loss": 0.1717,
      "step": 7650
    },
    {
      "epoch": 20.58882569421211,
      "grad_norm": 1.8554657697677612,
      "learning_rate": 5.315540992320422e-05,
      "loss": 0.1674,
      "step": 7700
    },
    {
      "epoch": 20.722649715623955,
      "grad_norm": 1.4022318124771118,
      "learning_rate": 5.1803084155339834e-05,
      "loss": 0.1682,
      "step": 7750
    },
    {
      "epoch": 20.8564737370358,
      "grad_norm": 1.225909948348999,
      "learning_rate": 5.0462143797125194e-05,
      "loss": 0.1557,
      "step": 7800
    },
    {
      "epoch": 20.990297758447642,
      "grad_norm": 1.1999216079711914,
      "learning_rate": 4.915937366151612e-05,
      "loss": 0.1819,
      "step": 7850
    },
    {
      "epoch": 21.123118099698896,
      "grad_norm": 1.1340886354446411,
      "learning_rate": 4.7841908274384616e-05,
      "loss": 0.1466,
      "step": 7900
    },
    {
      "epoch": 21.25694212111074,
      "grad_norm": 2.4632761478424072,
      "learning_rate": 4.6536764033335625e-05,
      "loss": 0.1533,
      "step": 7950
    },
    {
      "epoch": 21.390766142522583,
      "grad_norm": 2.1947731971740723,
      "learning_rate": 4.524424924859133e-05,
      "loss": 0.1525,
      "step": 8000
    },
    {
      "epoch": 21.390766142522583,
      "eval_cer": 45.74042150920314,
      "eval_loss": 0.6402448415756226,
      "eval_runtime": 4207.2305,
      "eval_samples_per_second": 0.355,
      "eval_steps_per_second": 0.089,
      "eval_wer": 83.26639892904953,
      "step": 8000
    },
    {
      "epoch": 21.524590163934427,
      "grad_norm": 1.4115179777145386,
      "learning_rate": 4.396466924695628e-05,
      "loss": 0.1577,
      "step": 8050
    },
    {
      "epoch": 21.65841418534627,
      "grad_norm": 0.9284841418266296,
      "learning_rate": 4.2698326299690796e-05,
      "loss": 0.1646,
      "step": 8100
    },
    {
      "epoch": 21.792238206758114,
      "grad_norm": 1.1636319160461426,
      "learning_rate": 4.144551955110656e-05,
      "loss": 0.1699,
      "step": 8150
    },
    {
      "epoch": 21.926062228169958,
      "grad_norm": 1.4965612888336182,
      "learning_rate": 4.020654494790042e-05,
      "loss": 0.1567,
      "step": 8200
    },
    {
      "epoch": 22.05888256942121,
      "grad_norm": 1.1289929151535034,
      "learning_rate": 3.898169516924398e-05,
      "loss": 0.148,
      "step": 8250
    },
    {
      "epoch": 22.192706590833055,
      "grad_norm": 1.0541123151779175,
      "learning_rate": 3.777125955764484e-05,
      "loss": 0.1365,
      "step": 8300
    },
    {
      "epoch": 22.3265306122449,
      "grad_norm": 1.2903773784637451,
      "learning_rate": 3.657552405059613e-05,
      "loss": 0.1498,
      "step": 8350
    },
    {
      "epoch": 22.460354633656742,
      "grad_norm": 1.170268177986145,
      "learning_rate": 3.5394771113030356e-05,
      "loss": 0.1393,
      "step": 8400
    },
    {
      "epoch": 22.594178655068585,
      "grad_norm": 2.3961639404296875,
      "learning_rate": 3.422927967059354e-05,
      "loss": 0.1537,
      "step": 8450
    },
    {
      "epoch": 22.72800267648043,
      "grad_norm": 1.6885138750076294,
      "learning_rate": 3.3079325043755495e-05,
      "loss": 0.1517,
      "step": 8500
    },
    {
      "epoch": 22.72800267648043,
      "eval_cer": 43.13240282489018,
      "eval_loss": 0.6616063117980957,
      "eval_runtime": 4264.9447,
      "eval_samples_per_second": 0.35,
      "eval_steps_per_second": 0.088,
      "eval_wer": 83.46720214190094,
      "step": 8500
    },
    {
      "epoch": 22.861826697892273,
      "grad_norm": 1.224103569984436,
      "learning_rate": 3.194517888277183e-05,
      "loss": 0.1464,
      "step": 8550
    },
    {
      "epoch": 22.995650719304116,
      "grad_norm": 1.8937016725540161,
      "learning_rate": 3.0827109103512643e-05,
      "loss": 0.1515,
      "step": 8600
    },
    {
      "epoch": 23.12847106055537,
      "grad_norm": 0.9321218729019165,
      "learning_rate": 2.972537982417366e-05,
      "loss": 0.1314,
      "step": 8650
    },
    {
      "epoch": 23.262295081967213,
      "grad_norm": 4.241806507110596,
      "learning_rate": 2.8640251302884437e-05,
      "loss": 0.1546,
      "step": 8700
    },
    {
      "epoch": 23.396119103379057,
      "grad_norm": 1.5531649589538574,
      "learning_rate": 2.7571979876228403e-05,
      "loss": 0.1466,
      "step": 8750
    },
    {
      "epoch": 23.5299431247909,
      "grad_norm": 0.8598953485488892,
      "learning_rate": 2.6520817898689155e-05,
      "loss": 0.1293,
      "step": 8800
    },
    {
      "epoch": 23.663767146202744,
      "grad_norm": 0.94212406873703,
      "learning_rate": 2.5487013683037574e-05,
      "loss": 0.1334,
      "step": 8850
    },
    {
      "epoch": 23.797591167614588,
      "grad_norm": 1.301113247871399,
      "learning_rate": 2.4470811441673736e-05,
      "loss": 0.1387,
      "step": 8900
    },
    {
      "epoch": 23.93141518902643,
      "grad_norm": 1.6591776609420776,
      "learning_rate": 2.3472451228937253e-05,
      "loss": 0.1322,
      "step": 8950
    },
    {
      "epoch": 24.064235530277685,
      "grad_norm": 2.3827741146087646,
      "learning_rate": 2.2492168884400033e-05,
      "loss": 0.1331,
      "step": 9000
    },
    {
      "epoch": 24.064235530277685,
      "eval_cer": 39.52343880331424,
      "eval_loss": 0.680834949016571,
      "eval_runtime": 3937.3171,
      "eval_samples_per_second": 0.379,
      "eval_steps_per_second": 0.095,
      "eval_wer": 82.93172690763052,
      "step": 9000
    },
    {
      "epoch": 24.19805955168953,
      "grad_norm": 1.2200859785079956,
      "learning_rate": 2.1530195977154554e-05,
      "loss": 0.1329,
      "step": 9050
    },
    {
      "epoch": 24.331883573101372,
      "grad_norm": 0.8970509767532349,
      "learning_rate": 2.0586759751111208e-05,
      "loss": 0.137,
      "step": 9100
    },
    {
      "epoch": 24.465707594513216,
      "grad_norm": 0.9381316900253296,
      "learning_rate": 1.9662083071316874e-05,
      "loss": 0.1268,
      "step": 9150
    },
    {
      "epoch": 24.59953161592506,
      "grad_norm": 1.3403384685516357,
      "learning_rate": 1.875638437130841e-05,
      "loss": 0.1308,
      "step": 9200
    },
    {
      "epoch": 24.733355637336903,
      "grad_norm": 1.4032477140426636,
      "learning_rate": 1.7869877601512662e-05,
      "loss": 0.1373,
      "step": 9250
    },
    {
      "epoch": 24.867179658748746,
      "grad_norm": 1.1638526916503906,
      "learning_rate": 1.7002772178705716e-05,
      "loss": 0.1325,
      "step": 9300
    },
    {
      "epoch": 25.0,
      "grad_norm": 1.3279180526733398,
      "learning_rate": 1.6155272936542898e-05,
      "loss": 0.1346,
      "step": 9350
    },
    {
      "epoch": 25.133824021411844,
      "grad_norm": 1.049393653869629,
      "learning_rate": 1.5327580077171587e-05,
      "loss": 0.1237,
      "step": 9400
    },
    {
      "epoch": 25.267648042823687,
      "grad_norm": 1.8824130296707153,
      "learning_rate": 1.4519889123938079e-05,
      "loss": 0.1233,
      "step": 9450
    },
    {
      "epoch": 25.40147206423553,
      "grad_norm": 1.0555213689804077,
      "learning_rate": 1.3732390875199785e-05,
      "loss": 0.1193,
      "step": 9500
    },
    {
      "epoch": 25.40147206423553,
      "eval_cer": 39.53734082188734,
      "eval_loss": 0.6913416385650635,
      "eval_runtime": 4057.7542,
      "eval_samples_per_second": 0.368,
      "eval_steps_per_second": 0.092,
      "eval_wer": 84.47121820615796,
      "step": 9500
    },
    {
      "epoch": 25.535296085647374,
      "grad_norm": 1.3966970443725586,
      "learning_rate": 1.2965271359253373e-05,
      "loss": 0.1275,
      "step": 9550
    },
    {
      "epoch": 25.669120107059218,
      "grad_norm": 1.2734872102737427,
      "learning_rate": 1.2218711790389959e-05,
      "loss": 0.1192,
      "step": 9600
    },
    {
      "epoch": 25.80294412847106,
      "grad_norm": 1.767448902130127,
      "learning_rate": 1.149288852608743e-05,
      "loss": 0.1315,
      "step": 9650
    },
    {
      "epoch": 25.936768149882905,
      "grad_norm": 1.7853336334228516,
      "learning_rate": 1.0787973025349995e-05,
      "loss": 0.1314,
      "step": 9700
    },
    {
      "epoch": 26.06958849113416,
      "grad_norm": 1.2791922092437744,
      "learning_rate": 1.0104131808205008e-05,
      "loss": 0.1246,
      "step": 9750
    },
    {
      "epoch": 26.203412512546002,
      "grad_norm": 1.2864367961883545,
      "learning_rate": 9.441526416366398e-06,
      "loss": 0.1268,
      "step": 9800
    },
    {
      "epoch": 26.337236533957846,
      "grad_norm": 1.322190523147583,
      "learning_rate": 8.800313375074243e-06,
      "loss": 0.1162,
      "step": 9850
    },
    {
      "epoch": 26.47106055536969,
      "grad_norm": 0.9996235370635986,
      "learning_rate": 8.18064415611921e-06,
      "loss": 0.1138,
      "step": 9900
    },
    {
      "epoch": 26.604884576781533,
      "grad_norm": 1.90705406665802,
      "learning_rate": 7.582665142060863e-06,
      "loss": 0.121,
      "step": 9950
    },
    {
      "epoch": 26.738708598193377,
      "grad_norm": 1.1643750667572021,
      "learning_rate": 7.0065175916482095e-06,
      "loss": 0.1215,
      "step": 10000
    },
    {
      "epoch": 26.738708598193377,
      "eval_cer": 41.61708280042262,
      "eval_loss": 0.706569492816925,
      "eval_runtime": 4107.1349,
      "eval_samples_per_second": 0.364,
      "eval_steps_per_second": 0.091,
      "eval_wer": 84.67202141900937,
      "step": 10000
    },
    {
      "epoch": 26.87253261960522,
      "grad_norm": 1.5611836910247803,
      "learning_rate": 6.452337606450465e-06,
      "loss": 0.1156,
      "step": 10050
    },
    {
      "epoch": 27.005352960856474,
      "grad_norm": 1.1766977310180664,
      "learning_rate": 5.9202560987063785e-06,
      "loss": 0.1158,
      "step": 10100
    },
    {
      "epoch": 27.139176982268317,
      "grad_norm": 1.1133205890655518,
      "learning_rate": 5.410398760399027e-06,
      "loss": 0.1221,
      "step": 10150
    },
    {
      "epoch": 27.27300100368016,
      "grad_norm": 1.0748997926712036,
      "learning_rate": 4.922886033564156e-06,
      "loss": 0.1199,
      "step": 10200
    },
    {
      "epoch": 27.406825025092004,
      "grad_norm": 0.8697709441184998,
      "learning_rate": 4.4578330818383915e-06,
      "loss": 0.1204,
      "step": 10250
    },
    {
      "epoch": 27.540649046503848,
      "grad_norm": 1.1457148790359497,
      "learning_rate": 4.015349763254617e-06,
      "loss": 0.1177,
      "step": 10300
    },
    {
      "epoch": 27.67447306791569,
      "grad_norm": 1.6215219497680664,
      "learning_rate": 3.595540604290437e-06,
      "loss": 0.116,
      "step": 10350
    },
    {
      "epoch": 27.808297089327535,
      "grad_norm": 2.964731454849243,
      "learning_rate": 3.1985047751762697e-06,
      "loss": 0.1076,
      "step": 10400
    },
    {
      "epoch": 27.94212111073938,
      "grad_norm": 1.3723204135894775,
      "learning_rate": 2.8243360664686248e-06,
      "loss": 0.1177,
      "step": 10450
    },
    {
      "epoch": 28.074941451990632,
      "grad_norm": 1.3119738101959229,
      "learning_rate": 2.4731228668943175e-06,
      "loss": 0.1147,
      "step": 10500
    },
    {
      "epoch": 28.074941451990632,
      "eval_cer": 41.16665739865428,
      "eval_loss": 0.7086213231086731,
      "eval_runtime": 4116.9399,
      "eval_samples_per_second": 0.363,
      "eval_steps_per_second": 0.091,
      "eval_wer": 84.67202141900937,
      "step": 10500
    },
    {
      "epoch": 28.208765473402476,
      "grad_norm": 1.884497880935669,
      "learning_rate": 2.1449481424706042e-06,
      "loss": 0.1131,
      "step": 10550
    },
    {
      "epoch": 28.34258949481432,
      "grad_norm": 1.7668406963348389,
      "learning_rate": 1.8398894169063707e-06,
      "loss": 0.1201,
      "step": 10600
    },
    {
      "epoch": 28.476413516226163,
      "grad_norm": 1.1700961589813232,
      "learning_rate": 1.5580187532890033e-06,
      "loss": 0.105,
      "step": 10650
    },
    {
      "epoch": 28.610237537638007,
      "grad_norm": 1.6085224151611328,
      "learning_rate": 1.2994027370611173e-06,
      "loss": 0.11,
      "step": 10700
    },
    {
      "epoch": 28.74406155904985,
      "grad_norm": 1.281330943107605,
      "learning_rate": 1.0641024602912497e-06,
      "loss": 0.1192,
      "step": 10750
    },
    {
      "epoch": 28.877885580461694,
      "grad_norm": 1.1648045778274536,
      "learning_rate": 8.521735072423154e-07,
      "loss": 0.1175,
      "step": 10800
    },
    {
      "epoch": 29.010705921712947,
      "grad_norm": 1.080080270767212,
      "learning_rate": 6.636659412410762e-07,
      "loss": 0.119,
      "step": 10850
    },
    {
      "epoch": 29.14452994312479,
      "grad_norm": 1.491408348083496,
      "learning_rate": 4.98624292851857e-07,
      "loss": 0.1205,
      "step": 10900
    },
    {
      "epoch": 29.278353964536635,
      "grad_norm": 1.308889389038086,
      "learning_rate": 3.5708754935720457e-07,
      "loss": 0.1141,
      "step": 10950
    },
    {
      "epoch": 29.412177985948478,
      "grad_norm": 2.551973819732666,
      "learning_rate": 2.3908914554805486e-07,
      "loss": 0.1197,
      "step": 11000
    },
    {
      "epoch": 29.412177985948478,
      "eval_cer": 38.80053383751321,
      "eval_loss": 0.7113893628120422,
      "eval_runtime": 4078.0125,
      "eval_samples_per_second": 0.366,
      "eval_steps_per_second": 0.092,
      "eval_wer": 84.60508701472557,
      "step": 11000
    }
  ],
  "logging_steps": 50,
  "max_steps": 11220,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2032327023460352e+21,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
